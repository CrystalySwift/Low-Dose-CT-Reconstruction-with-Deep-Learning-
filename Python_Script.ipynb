{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Filtered Back Projection (3D)**"
      ],
      "metadata": {
        "id": "bBxdRjqLDy8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjQFJF9FDwXI"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import odl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI FILE\n",
        "# ==========================================\n",
        "path_observation = \"/content/dataset_sementara/observation_validation_000.hdf5\"\n",
        "path_ground_truth = \"/content/dataset_sementara/ground_truth_validation_000.hdf5\"\n",
        "\n",
        "# ==========================================\n",
        "# 2. SETUP GEOMETRI ODL\n",
        "# ==========================================\n",
        "print(\"‚öôÔ∏è Menyiapkan Geometri & GPU...\")\n",
        "\n",
        "reco_space = odl.uniform_discr(\n",
        "    min_pt=[-0.13, -0.13], max_pt=[0.13, 0.13], shape=[362, 362], dtype='float32'\n",
        ")\n",
        "angle_partition = odl.uniform_partition(0, np.pi, 1000)\n",
        "detector_partition = odl.uniform_partition(-0.19, 0.19, 513)\n",
        "geometry = odl.tomo.Parallel2dGeometry(angle_partition, detector_partition)\n",
        "\n",
        "try:\n",
        "    operator = odl.tomo.RayTransform(reco_space, geometry, impl='astra_cuda')\n",
        "    print(\"‚úÖ GPU T4 Aktif (astra_cuda).\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è GPU Gagal, pakai CPU. Akan lambat.\")\n",
        "    operator = odl.tomo.RayTransform(reco_space, geometry, impl='astra_cpu')\n",
        "\n",
        "fbp = odl.tomo.fbp_op(operator)\n",
        "\n",
        "# ==========================================\n",
        "# 3. PROSES REKONSTRUKSI VOLUME\n",
        "# ==========================================\n",
        "def reconstruct_volume_3d():\n",
        "    print(f\"üöÄ Memproses file: {path_observation}\")\n",
        "\n",
        "    with h5py.File(path_observation, 'r') as f_obs:\n",
        "        data_sinogram = f_obs['data'][:]\n",
        "        num_slices = data_sinogram.shape[0]\n",
        "\n",
        "        print(f\"   Jumlah Slice dalam file: {num_slices}\")\n",
        "        print(\"   ‚è≥ Sedang merekonstruksi seluruh volume (mohon tunggu)...\")\n",
        "\n",
        "        # Wadah untuk menumpuk hasil (Volume 3D)\n",
        "        volume_3d = np.zeros((num_slices, 362, 362), dtype=np.float32)\n",
        "\n",
        "        for i in range(num_slices):\n",
        "            sino = data_sinogram[i]\n",
        "\n",
        "            rec = fbp(sino).asarray()\n",
        "\n",
        "            rec = (rec - np.min(rec)) / (np.max(rec) - np.min(rec) + 1e-8)\n",
        "\n",
        "            volume_3d[i, :, :] = rec\n",
        "\n",
        "            if (i+1) % 20 == 0:\n",
        "                print(f\"   Processed {i+1}/{num_slices}...\")\n",
        "\n",
        "        print(f\"‚úÖ Selesai! Volume 3D terbentuk.\")\n",
        "        print(f\"üì¶ Dimensi Akhir: {volume_3d.shape} -> (Z, Y, X)\")\n",
        "\n",
        "        return volume_3d\n",
        "\n",
        "volume_hasil = reconstruct_volume_3d()\n",
        "\n",
        "# ==========================================\n",
        "# 4. VISUALISASI PERBEDAAN (ORTHOGONAL VIEW)\n",
        "# ==========================================\n",
        "\n",
        "def show_3d_slices(vol):\n",
        "    z, y, x = vol.shape\n",
        "\n",
        "    # Ambil irisan tengah dari masing-masing sumbu\n",
        "    slice_axial = vol[z // 2, :, :]      # Pandangan dari Atas (Standar CT)\n",
        "    slice_coronal = vol[:, y // 2, :]    # Pandangan dari Depan\n",
        "    slice_sagittal = vol[:, :, x // 2]   # Pandangan dari Samping\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 1. Axial View (X-Y)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(slice_axial, cmap='gray')\n",
        "    plt.title(f\"1. Axial View (Atas)\\nSlice Z={z//2}\")\n",
        "    plt.xlabel(\"X axis\"); plt.ylabel(\"Y axis\")\n",
        "\n",
        "    # 2. Coronal View (X-Z)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(np.rot90(slice_coronal), cmap='gray')\n",
        "    plt.title(f\"2. Coronal View (Depan)\\nSlice Y={y//2}\")\n",
        "    plt.xlabel(\"X axis\"); plt.ylabel(\"Z axis (Tumpukan)\")\n",
        "\n",
        "    # 3. Sagittal View (Y-Z)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(np.rot90(slice_sagittal), cmap='gray')\n",
        "    plt.title(f\"3. Sagittal View (Samping)\\nSlice X={x//2}\")\n",
        "    plt.xlabel(\"Y axis\"); plt.ylabel(\"Z axis (Tumpukan)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nüìä Menampilkan Visualisasi 3D Orthogonal...\")\n",
        "show_3d_slices(volume_hasil)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Micro-patching**\n",
        "\n",
        "Results were only used for Res-Att U-net"
      ],
      "metadata": {
        "id": "_UaGuubmJx7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import gc\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI PATH\n",
        "# ==========================================\n",
        "\n",
        "# A. Folder Input FBP (Dari Google Drive - .npy)\n",
        "input_drive_folder = \"/content/drive/MyDrive/Finpro Pencit/HDF5/Hasil FBP/\"\n",
        "\n",
        "# B. Folder Ground Truth (Dari Lokal Colab - .hdf5)\n",
        "gt_local_folder = \"/content/dataset_sementara_GT/\"\n",
        "\n",
        "# C. Folder Output (Ke Google Drive - .npy Patches)\n",
        "output_folder = \"/content/drive/MyDrive/Finpro Pencit/HDF5/Training_Patches/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Parameter Patching\n",
        "PATCH_SIZE = (32, 32, 32)\n",
        "STRIDE = (16, 16, 16)\n",
        "THRESHOLD_AIR = 0.1\n",
        "\n",
        "print(f\"üìÇ Input FBP (Drive): {input_drive_folder}\")\n",
        "print(f\"üìÇ Input GT (Lokal): {gt_local_folder}\")\n",
        "print(f\"üíæ Output Patches: {output_folder}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. EKSEKUSI BATCH HYBRID\n",
        "# ==========================================\n",
        "def process_patching_hybrid():\n",
        "    search_pattern = os.path.join(input_drive_folder, \"processed_input_*.npy\")\n",
        "    list_files = sorted(glob.glob(search_pattern))\n",
        "\n",
        "    if len(list_files) == 0:\n",
        "        print(\"‚ùå Tidak ada file Input FBP (.npy) di Drive.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüéØ Memulai Patching untuk {len(list_files)} file pasangan.\\n\")\n",
        "\n",
        "    for i, input_path in enumerate(list_files):\n",
        "        # 1. Identifikasi File\n",
        "        filename_npy = os.path.basename(input_path)\n",
        "        file_id = filename_npy.split('_')[-1].replace('.npy', '')\n",
        "\n",
        "        print(f\"üî™ [{i+1}/{len(list_files)}] Memproses ID: {file_id}\")\n",
        "\n",
        "        # 2. Cari Pasangan GT HDF5 di Lokal\n",
        "        gt_filename = f\"ground_truth_validation_{file_id}.hdf5\"\n",
        "        gt_path = os.path.join(gt_local_folder, gt_filename)\n",
        "\n",
        "        if not os.path.exists(gt_path):\n",
        "            print(f\"   ‚ö†Ô∏è SKIP: File GT {gt_filename} tidak ada di {gt_local_folder}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # A. Load Input FBP (NPY dari Drive)\n",
        "            vol_input = np.load(input_path)\n",
        "\n",
        "            # B. Load Target GT (HDF5 dari Lokal)\n",
        "            with h5py.File(gt_path, 'r') as f_gt:\n",
        "                valid_slices = vol_input.shape[0]\n",
        "\n",
        "                vol_target_raw = f_gt['data'][:valid_slices] # Ambil sejumlah input\n",
        "\n",
        "                vol_target = (vol_target_raw - np.min(vol_target_raw)) / \\\n",
        "                             (np.max(vol_target_raw) - np.min(vol_target_raw) + 1e-8)\n",
        "\n",
        "            if vol_input.shape != vol_target.shape:\n",
        "                print(f\"   ‚ùå Dimensi beda! Input:{vol_input.shape} vs Target:{vol_target.shape}\")\n",
        "                continue\n",
        "\n",
        "            # --- PROSES PATCHING ---\n",
        "            batch_patches_input = []\n",
        "            batch_patches_target = []\n",
        "\n",
        "            z_len, y_len, x_len = vol_input.shape\n",
        "            pz, py, px = PATCH_SIZE\n",
        "            sz, sy, sx = STRIDE\n",
        "\n",
        "            for z in range(0, z_len - pz + 1, sz):\n",
        "                for y in range(0, y_len - py + 1, sy):\n",
        "                    for x in range(0, x_len - px + 1, sx):\n",
        "\n",
        "                        # Cek Threshold\n",
        "                        patch_check = vol_target[z:z+pz, y:y+py, x:x+px]\n",
        "\n",
        "                        if np.mean(patch_check) > THRESHOLD_AIR:\n",
        "                            p_in = vol_input[z:z+pz, y:y+py, x:x+px]\n",
        "                            p_gt = vol_target[z:z+pz, y:y+py, x:x+px]\n",
        "\n",
        "                            batch_patches_input.append(p_in)\n",
        "                            batch_patches_target.append(p_gt)\n",
        "\n",
        "            # --- SIMPAN KE DRIVE ---\n",
        "            if len(batch_patches_input) > 0:\n",
        "                np_in = np.array(batch_patches_input, dtype=np.float32)\n",
        "                np_gt = np.array(batch_patches_target, dtype=np.float32)\n",
        "\n",
        "                save_name_in = os.path.join(output_folder, f\"patch_in_{file_id}.npy\")\n",
        "                save_name_gt = os.path.join(output_folder, f\"patch_gt_{file_id}.npy\")\n",
        "\n",
        "                np.save(save_name_in, np_in)\n",
        "                np.save(save_name_gt, np_gt)\n",
        "\n",
        "                print(f\"   ‚úÖ Disimpan: {len(batch_patches_input)} patches.\")\n",
        "            else:\n",
        "                print(\"   ‚ö†Ô∏è File ini kosong/hanya udara.\")\n",
        "\n",
        "            del vol_input, vol_target, vol_target_raw\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "    print(\"\\nüéâ SELESAI! Semua patch siap training di Drive.\")\n",
        "\n",
        "process_patching_hybrid()"
      ],
      "metadata": {
        "id": "m665T6dkJ4Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3D Residual-Attention U-shaped Convolutional Neural Network (U-net)**"
      ],
      "metadata": {
        "id": "u4sEeKkkJ4wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training & Validation**"
      ],
      "metadata": {
        "id": "AlBoJPlDLc3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pytorch_msssim import ssim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import bisect\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI\n",
        "# ==========================================\n",
        "data_folder = \"/content/drive/MyDrive/Finpro Pencit/HDF5/Training_Patches/\"\n",
        "\n",
        "experiment_name = \"Run_Final_V6_LimitBatch\"\n",
        "\n",
        "output_dir = f\"/content/drive/MyDrive/Finpro Pencit/Training_Logs/{experiment_name}/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 2\n",
        "NUM_WORKERS = 0\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# PEMBAGIAN DATA\n",
        "TEST_SPLIT = 0.10\n",
        "VAL_SPLIT = 0.20\n",
        "\n",
        "# LIMIT BATCH (Agar Epoch Cepat)\n",
        "TRAIN_BATCH_LIMIT = 2000\n",
        "VAL_BATCH_LIMIT = 200\n",
        "\n",
        "print(f\"üìÇ Folder Output: {output_dir}\")\n",
        "print(f\"‚è±Ô∏è Limit Batch: {TRAIN_BATCH_LIMIT} per Epoch\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. KOMPONEN DATASET & MODEL\n",
        "# ==========================================\n",
        "class LoDoPaBDataset(Dataset):\n",
        "    def __init__(self, folder_path):\n",
        "        self.folder_path = folder_path\n",
        "        self.input_files = sorted(glob.glob(os.path.join(folder_path, \"patch_in_*.npy\")))\n",
        "        if len(self.input_files) == 0:\n",
        "            raise RuntimeError(f\"‚ùå Error: Tidak ada file .npy di {folder_path}\")\n",
        "\n",
        "        print(f\"üîÑ Mengindeks {len(self.input_files)} file... (Lazy Loading)\")\n",
        "        self.file_indices = []\n",
        "        self.cumulative_indices = [0]\n",
        "        for f_path in self.input_files:\n",
        "            data = np.load(f_path, mmap_mode='r')\n",
        "            num = data.shape[0]\n",
        "            self.file_indices.append(num)\n",
        "            self.cumulative_indices.append(self.cumulative_indices[-1] + num)\n",
        "        self.total_patches = self.cumulative_indices[-1]\n",
        "        print(f\"‚úÖ Total Data: {self.total_patches} patches\")\n",
        "\n",
        "    def __len__(self): return self.total_patches\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_idx = bisect.bisect_right(self.cumulative_indices, idx) - 1\n",
        "        local_idx = idx - self.cumulative_indices[file_idx]\n",
        "\n",
        "        input_path = self.input_files[file_idx]\n",
        "        filename = os.path.basename(input_path)\n",
        "        target_path = os.path.join(self.folder_path, filename.replace(\"patch_in\", \"patch_gt\"))\n",
        "\n",
        "        d_in = np.load(input_path, mmap_mode='r')\n",
        "        d_gt = np.load(target_path, mmap_mode='r')\n",
        "\n",
        "        p_in = np.array(d_in[local_idx]).astype(np.float32)\n",
        "        p_gt = np.array(d_gt[local_idx]).astype(np.float32)\n",
        "\n",
        "        return torch.from_numpy(np.expand_dims(p_in, axis=0)), torch.from_numpy(np.expand_dims(p_gt, axis=0))\n",
        "\n",
        "# --- MODEL ARSITEKTUR (Fixed) ---\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(in_c, out_c, 3, padding=1), nn.BatchNorm3d(out_c), nn.ReLU(True),\n",
        "            nn.Conv3d(out_c, out_c, 3, padding=1), nn.BatchNorm3d(out_c))\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.sc = nn.Conv3d(in_c, out_c, 1) if in_c != out_c else nn.Sequential()\n",
        "    def forward(self, x): return self.relu(self.conv(x) + self.sc(x))\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super().__init__()\n",
        "        self.Wg = nn.Sequential(nn.Conv3d(F_g, F_int, 1), nn.BatchNorm3d(F_int))\n",
        "        self.Wx = nn.Sequential(nn.Conv3d(F_l, F_int, 1), nn.BatchNorm3d(F_int))\n",
        "        self.psi = nn.Sequential(nn.Conv3d(F_int, 1, 1), nn.BatchNorm3d(1), nn.Sigmoid())\n",
        "        self.relu = nn.ReLU(True)\n",
        "    def forward(self, g, x):\n",
        "        psi = self.relu(self.Wg(g) + self.Wx(x))\n",
        "        return x * self.psi(psi)\n",
        "\n",
        "class Lightweight3DUNet(nn.Module):\n",
        "    def __init__(self, in_c=1, out_c=1):\n",
        "        super().__init__()\n",
        "        f = [16, 32, 64, 128]\n",
        "        self.enc1 = ResBlock(in_c, f[0]); self.p1 = nn.MaxPool3d(2)\n",
        "        self.enc2 = ResBlock(f[0], f[1]); self.p2 = nn.MaxPool3d(2)\n",
        "        self.enc3 = ResBlock(f[1], f[2]); self.p3 = nn.MaxPool3d(2)\n",
        "        self.bot = ResBlock(f[2], f[3])\n",
        "\n",
        "        self.up3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att3 = AttentionBlock(f[3], f[2], f[2])\n",
        "        self.dec3 = ResBlock(f[3]+f[2], f[2])\n",
        "\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att2 = AttentionBlock(f[2], f[1], f[1])\n",
        "        self.dec2 = ResBlock(f[2]+f[1], f[1])\n",
        "\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att1 = AttentionBlock(f[1], f[0], f[0])\n",
        "        self.dec1 = ResBlock(f[1]+f[0], f[0])\n",
        "\n",
        "        self.out = nn.Conv3d(f[0], out_c, 1)\n",
        "        self.dropout = nn.Dropout3d(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x); p1 = self.p1(e1)\n",
        "        e2 = self.enc2(p1); p2 = self.p2(e2)\n",
        "        e3 = self.enc3(p2); p3 = self.p3(e3)\n",
        "        b = self.bot(p3)\n",
        "\n",
        "        d3 = self.up3(b); x3 = self.att3(d3, e3); d3 = self.dec3(torch.cat([x3, d3], 1))\n",
        "        d2 = self.up2(d3); x2 = self.att2(d2, e2); d2 = self.dec2(torch.cat([x2, d2], 1))\n",
        "        d1 = self.up1(d2); x1 = self.att1(d1, e1); d1 = self.dec1(torch.cat([x1, d1], 1))\n",
        "        return self.out(self.dropout(d1))\n",
        "\n",
        "class GradientLoss3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        k = torch.FloatTensor([[[[-1,0,1],[-2,0,2],[-1,0,1]],[[-2,0,2],[-4,0,4],[-2,0,2]],[[-1,0,1],[-2,0,2],[-1,0,1]]]])\n",
        "        self.k = nn.Parameter(k.unsqueeze(1), requires_grad=False)\n",
        "    def forward(self, p, t):\n",
        "        if p.device != self.k.device: self.k = self.k.to(p.device)\n",
        "        gp = torch.abs(torch.nn.functional.conv3d(p, self.k, padding=1))\n",
        "        gt = torch.abs(torch.nn.functional.conv3d(t, self.k, padding=1))\n",
        "        return torch.mean(torch.abs(gp - gt))\n",
        "\n",
        "def composite_loss(p, t, g_fn):\n",
        "    return nn.MSELoss()(p, t) + 0.1*(1-ssim(p, t, data_range=1.0, size_average=True)) + 0.01*g_fn(p, t)\n",
        "\n",
        "# ==========================================\n",
        "# 3. PERSIAPAN DATA & AUTO-RESUME\n",
        "# ==========================================\n",
        "full_ds = LoDoPaBDataset(data_folder)\n",
        "total_len = len(full_ds)\n",
        "test_len = int(total_len * TEST_SPLIT)\n",
        "val_len = int(total_len * VAL_SPLIT)\n",
        "train_len = total_len - val_len - test_len\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(full_ds, [train_len, val_len, test_len])\n",
        "print(f\"üìä SPLIT DATA: Train={len(train_ds)} | Val={len(val_ds)} | Test={len(test_ds)} (Disisihkan)\")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Lightweight3DUNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "grad_fn = GradientLoss3D().to(device)\n",
        "\n",
        "# --- LOGIKA RESUME ---\n",
        "start_epoch = 0\n",
        "best_val_loss = float('inf')\n",
        "log_history = []\n",
        "csv_path = os.path.join(output_dir, \"training_log.csv\")\n",
        "\n",
        "checkpoints = glob.glob(os.path.join(output_dir, \"checkpoint_ep*.pth\"))\n",
        "if len(checkpoints) > 0:\n",
        "    latest = max(checkpoints, key=os.path.getctime)\n",
        "    print(f\"\\nüîÑ Melanjutkan dari: {os.path.basename(latest)}\")\n",
        "    model.load_state_dict(torch.load(latest, map_location=device))\n",
        "    try: start_epoch = int(latest.split('_ep')[-1].replace('.pth',''))\n",
        "    except: start_epoch = 0\n",
        "\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        log_history = df.to_dict('records')\n",
        "        if len(log_history) > 0: best_val_loss = min([x['val_loss'] for x in log_history])\n",
        "        print(f\"üìà History: {len(log_history)} epoch terpulihkan.\")\n",
        "else:\n",
        "    print(\"\\nüÜï Memulai Training Baru.\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING LOOP (VERBOSE & LIMITED)\n",
        "# ==========================================\n",
        "print(f\"üî• START TRAINING (Epoch {start_epoch+1}/{NUM_EPOCHS})\")\n",
        "\n",
        "for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "    t0 = time.time()\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # Train Loop (Limit Batch)\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        if i >= TRAIN_BATCH_LIMIT: break # Limit check\n",
        "\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = composite_loss(out, y, grad_fn)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        count += 1\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f\"   [Epoch {epoch+1}] Batch {i+1}/{TRAIN_BATCH_LIMIT} | Loss: {loss.item():.5f}\")\n",
        "\n",
        "    avg_train = train_loss / count if count > 0 else 0\n",
        "\n",
        "    # Validation Loop\n",
        "    print(f\"   ‚è≥ Validasi...\")\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    v_count = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(val_loader):\n",
        "            if i >= VAL_BATCH_LIMIT: break\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            val_loss += composite_loss(model(x), y, grad_fn).item()\n",
        "            v_count += 1\n",
        "\n",
        "    avg_val = val_loss / v_count if v_count > 0 else 0\n",
        "    dt = (time.time() - t0)/60\n",
        "\n",
        "    print(f\"‚úÖ Epoch {epoch+1} Selesai ({dt:.1f}m) | Train: {avg_train:.5f} | Val: {avg_val:.5f}\")\n",
        "\n",
        "    # Save & Log\n",
        "    log_history.append({'epoch': epoch+1, 'train_loss': avg_train, 'val_loss': avg_val, 'time_m': dt})\n",
        "    pd.DataFrame(log_history).to_csv(csv_path, index=False)\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, f\"checkpoint_ep{epoch+1}.pth\"))\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save(model.state_dict(), os.path.join(output_dir, \"best_model.pth\"))\n",
        "        print(f\"   üèÜ New Best Model Saved!\")\n",
        "\n",
        "    if epoch > 3:\n",
        "        old = os.path.join(output_dir, f\"checkpoint_ep{epoch-2}.pth\")\n",
        "        if os.path.exists(old): os.remove(old)\n",
        "\n",
        "# ==========================================\n",
        "# 5. POST-TRAINING REPORT (SPECS & PLOT)\n",
        "# ==========================================\n",
        "print(\"\\nüéâ TRAINING SELESAI! Menampilkan Laporan Lengkap...\")\n",
        "\n",
        "# A. Spesifikasi Model\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"ü§ñ SPESIFIKASI MODEL\")\n",
        "print(\"=\"*30)\n",
        "print(f\"Model Name      : Lightweight 3D Res-Att U-Net\")\n",
        "print(f\"Total Parameter : {total_params:,} parameters\")\n",
        "print(f\"Input Shape     : (Batch, 1, 32, 32, 32)\")\n",
        "print(f\"Filters Config  : [16, 32, 64, 128]\")\n",
        "print(f\"Dropout Rate    : 0.2 (Monte Carlo Ready)\")\n",
        "print(f\"Loss Function   : Composite (MSE + SSIM + Gradient)\")\n",
        "print(\"=\"*30 + \"\\n\")\n",
        "\n",
        "# B. Plot Grafik Training\n",
        "if len(log_history) > 0:\n",
        "    df = pd.DataFrame(log_history)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(df['epoch'], df['train_loss'], label='Training Loss', marker='o', linestyle='-')\n",
        "    plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', marker='s', linestyle='--')\n",
        "\n",
        "    plt.title(f\"Training History: {experiment_name}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Composite Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plot_path = os.path.join(output_dir, \"final_training_plot.png\")\n",
        "    plt.savefig(plot_path, dpi=300)\n",
        "    print(f\"üìä Grafik disimpan di: {plot_path}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Tidak ada data log untuk di-plot.\")"
      ],
      "metadata": {
        "id": "gV1FpNmOLfuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing with Patch Data**"
      ],
      "metadata": {
        "id": "N3aw2eQqLqh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 0. SETUP & LIBRARY\n",
        "# ==========================================\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from tqdm import tqdm\n",
        "import bisect\n",
        "\n",
        "# Install Library SSIM CPU\n",
        "try:\n",
        "    from skimage.metrics import structural_similarity as ssim\n",
        "except ImportError:\n",
        "    !pip install scikit-image -q\n",
        "    from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI PATH (GOOGLE DRIVE)\n",
        "# ==========================================\n",
        "experiment_name = \"Run_Final_V6_LimitBatch\"\n",
        "base_output_dir = f\"/content/drive/MyDrive/Finpro Pencit/Output_Testing_Final/\"\n",
        "img_save_dir = os.path.join(base_output_dir, \"Visual_Evidence\")\n",
        "\n",
        "# Buat Folder\n",
        "os.makedirs(base_output_dir, exist_ok=True)\n",
        "os.makedirs(img_save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Hasil Analisis (Excel/Grafik) akan disimpan di: {base_output_dir}\")\n",
        "print(f\"üìÇ Bukti Gambar (PNG) akan disimpan di: {img_save_dir}\")\n",
        "\n",
        "# Path Data & Model\n",
        "data_folder = \"/content/drive/MyDrive/Finpro Pencit/Training_Patches\"\n",
        "checkpoint_path = f\"/content/drive/MyDrive/Finpro Pencit/Training_Logs/{experiment_name}/best_model.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. DEFINISI MODEL\n",
        "# ==========================================\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(in_c, out_c, 3, padding=1), nn.BatchNorm3d(out_c), nn.ReLU(True),\n",
        "            nn.Conv3d(out_c, out_c, 3, padding=1), nn.BatchNorm3d(out_c))\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.sc = nn.Conv3d(in_c, out_c, 1) if in_c != out_c else nn.Sequential()\n",
        "    def forward(self, x): return self.relu(self.conv(x) + self.sc(x))\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super().__init__()\n",
        "        self.Wg = nn.Sequential(nn.Conv3d(F_g, F_int, 1), nn.BatchNorm3d(F_int))\n",
        "        self.Wx = nn.Sequential(nn.Conv3d(F_l, F_int, 1), nn.BatchNorm3d(F_int))\n",
        "        self.psi = nn.Sequential(nn.Conv3d(F_int, 1, 1), nn.BatchNorm3d(1), nn.Sigmoid())\n",
        "        self.relu = nn.ReLU(True)\n",
        "    def forward(self, g, x):\n",
        "        psi = self.relu(self.Wg(g) + self.Wx(x))\n",
        "        return x * self.psi(psi)\n",
        "\n",
        "class Lightweight3DUNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super().__init__()\n",
        "        in_c, out_c = in_channels, out_channels\n",
        "        f = [16, 32, 64, 128]\n",
        "        self.enc1 = ResBlock(in_c, f[0]); self.p1 = nn.MaxPool3d(2)\n",
        "        self.enc2 = ResBlock(f[0], f[1]); self.p2 = nn.MaxPool3d(2)\n",
        "        self.enc3 = ResBlock(f[1], f[2]); self.p3 = nn.MaxPool3d(2)\n",
        "        self.bot = ResBlock(f[2], f[3])\n",
        "\n",
        "        self.up3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att3 = AttentionBlock(f[3], f[2], f[2])\n",
        "        self.dec3 = ResBlock(f[3]+f[2], f[2])\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att2 = AttentionBlock(f[2], f[1], f[1])\n",
        "        self.dec2 = ResBlock(f[2]+f[1], f[1])\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att1 = AttentionBlock(f[1], f[0], f[0])\n",
        "        self.dec1 = ResBlock(f[1]+f[0], f[0])\n",
        "        self.out = nn.Conv3d(f[0], out_c, 1)\n",
        "        self.dropout = nn.Dropout3d(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x); p1 = self.p1(e1)\n",
        "        e2 = self.enc2(p1); p2 = self.p2(e2)\n",
        "        e3 = self.enc3(p2); p3 = self.p3(e3)\n",
        "        b = self.bot(p3)\n",
        "\n",
        "        d3 = self.up3(b)\n",
        "        if d3.size() != e3.size(): d3 = F.interpolate(d3, size=e3.shape[2:], mode='trilinear', align_corners=True)\n",
        "        x3 = self.att3(d3, e3); d3 = self.dec3(torch.cat([x3, d3], 1))\n",
        "        d2 = self.up2(d3)\n",
        "        if d2.size() != e2.size(): d2 = F.interpolate(d2, size=e2.shape[2:], mode='trilinear', align_corners=True)\n",
        "        x2 = self.att2(d2, e2); d2 = self.dec2(torch.cat([x2, d2], 1))\n",
        "        d1 = self.up1(d2)\n",
        "        if d1.size() != e1.size(): d1 = F.interpolate(d1, size=e1.shape[2:], mode='trilinear', align_corners=True)\n",
        "        x1 = self.att1(d1, e1); d1 = self.dec1(torch.cat([x1, d1], 1))\n",
        "        return self.out(self.dropout(d1))\n",
        "\n",
        "UNet3D = Lightweight3DUNet\n",
        "\n",
        "# ==========================================\n",
        "# 3. DATASET & SPLIT\n",
        "# ==========================================\n",
        "class LoDoPaBDataset(Dataset):\n",
        "    def __init__(self, folder_path):\n",
        "        self.folder_path = folder_path\n",
        "        self.input_files = sorted(glob.glob(os.path.join(folder_path, \"patch_in_*.npy\")))\n",
        "        if len(self.input_files) == 0:\n",
        "            local_path = \"/content/data_lokal_patches/\"\n",
        "            if os.path.exists(local_path):\n",
        "                self.input_files = sorted(glob.glob(os.path.join(local_path, \"patch_in_*.npy\")))\n",
        "                self.folder_path = local_path\n",
        "\n",
        "        self.cumulative_indices = [0]\n",
        "        for f_path in self.input_files:\n",
        "            try:\n",
        "                data = np.load(f_path, mmap_mode='r')\n",
        "                self.cumulative_indices.append(self.cumulative_indices[-1] + data.shape[0])\n",
        "            except: pass\n",
        "        self.total_patches = self.cumulative_indices[-1]\n",
        "\n",
        "    def __len__(self): return self.total_patches\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_idx = bisect.bisect_right(self.cumulative_indices, idx) - 1\n",
        "        local_idx = idx - self.cumulative_indices[file_idx]\n",
        "\n",
        "        input_path = self.input_files[file_idx]\n",
        "        filename = os.path.basename(input_path)\n",
        "        target_path = os.path.join(self.folder_path, filename.replace(\"patch_in\", \"patch_gt\"))\n",
        "\n",
        "        d_in = np.load(input_path, mmap_mode='r')\n",
        "        d_gt = np.load(target_path, mmap_mode='r')\n",
        "\n",
        "        p_in = np.clip(np.array(d_in[local_idx]).astype(np.float32), 0, 1)\n",
        "        p_gt = np.clip(np.array(d_gt[local_idx]).astype(np.float32), 0, 1)\n",
        "\n",
        "        return torch.from_numpy(np.expand_dims(p_in, axis=0)), torch.from_numpy(np.expand_dims(p_gt, axis=0))\n",
        "\n",
        "# SETUP DATA SPLIT\n",
        "full_ds = LoDoPaBDataset(data_folder)\n",
        "total_len = len(full_ds)\n",
        "\n",
        "# Safety Logic\n",
        "if total_len < 20:\n",
        "    test_len = 2 # Minimal 2 data\n",
        "    val_len = 0\n",
        "    train_len = total_len - test_len\n",
        "else:\n",
        "    test_len = int(total_len * 0.10)\n",
        "    val_len = int(total_len * 0.20)\n",
        "    train_len = total_len - val_len - test_len\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "_, _, test_ds = random_split(full_ds, [train_len, val_len, test_len], generator=generator)\n",
        "\n",
        "print(f\"üìä Total Data Test (10%): {len(test_ds)} Patches\")\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "# ==========================================\n",
        "# 4. METRICS & RADIOMICS FUNCTIONS\n",
        "# ==========================================\n",
        "def calculate_metrics_numpy(pred, gt):\n",
        "    \"\"\"PSNR, RMSE, SSIM (CPU Version - Anti Error)\"\"\"\n",
        "    pred = pred.astype(np.float32)\n",
        "    gt = gt.astype(np.float32)\n",
        "\n",
        "    # 1. MSE & RMSE\n",
        "    mse = np.mean((pred - gt) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # 2. PSNR\n",
        "    if mse == 0: psnr = 100\n",
        "    else: psnr = 20 * np.log10(1.0 / rmse)\n",
        "\n",
        "    # 3. SSIM 3D\n",
        "    ssim_val = 0\n",
        "    D = gt.shape[0]\n",
        "    for z in range(D):\n",
        "        try:\n",
        "            s = ssim(gt[z], pred[z], data_range=1.0, win_size=3)\n",
        "        except ValueError:\n",
        "            s = ssim(gt[z], pred[z], data_range=1.0)\n",
        "        ssim_val += s\n",
        "\n",
        "    return psnr, ssim_val / D, rmse\n",
        "\n",
        "def get_radiomics(img_vol):\n",
        "    \"\"\"Radiomics Sederhana\"\"\"\n",
        "    flat = img_vol.flatten()\n",
        "    return {\n",
        "        'Mean': np.mean(flat),\n",
        "        'Std': np.std(flat),\n",
        "        'Skewness': skew(flat),\n",
        "        'Kurtosis': kurtosis(flat),\n",
        "        'Entropy': entropy(np.histogram(flat, bins=50)[0] + 1e-8)\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# 5. EXECUTION LOOP\n",
        "# ==========================================\n",
        "# Load Model\n",
        "model = UNet3D(in_channels=1, out_channels=1).to(device)\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "if 'model_state_dict' in checkpoint: model.load_state_dict(checkpoint['model_state_dict'])\n",
        "else: model.load_state_dict(checkpoint)\n",
        "\n",
        "metrics_log = []\n",
        "radiomics_log = []\n",
        "\n",
        "SAVE_IMG_LIMIT = 50\n",
        "img_saved_count = 0\n",
        "\n",
        "print(\"üöÄ Memulai Pengujian...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
        "        patient_id = f\"Test_Sample_{i+1:04d}\"\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # A. Prediksi Normal\n",
        "        model.eval()\n",
        "        output_std = model(inputs)\n",
        "\n",
        "        # B. Monte Carlo Uncertainty\n",
        "        uncertainty_vol = None\n",
        "        if img_saved_count < SAVE_IMG_LIMIT:\n",
        "            model.train()\n",
        "            mc_stack = []\n",
        "            for _ in range(5):\n",
        "                mc_stack.append(model(inputs).cpu().numpy())\n",
        "            uncertainty_vol = np.std(np.array(mc_stack), axis=0)[0, 0]\n",
        "\n",
        "        # C. Konversi Numpy\n",
        "        vol_in = inputs[0, 0].cpu().numpy()\n",
        "        vol_gt = targets[0, 0].cpu().numpy()\n",
        "        vol_out = output_std[0, 0].cpu().numpy()\n",
        "\n",
        "        # D. Hitung Metrik\n",
        "        psnr, ssim_val, rmse = calculate_metrics_numpy(vol_out, vol_gt)\n",
        "\n",
        "        # E. Hitung Radiomics\n",
        "        rad_gt = get_radiomics(vol_gt)\n",
        "        rad_out = get_radiomics(vol_out)\n",
        "\n",
        "        metrics_log.append({'ID': patient_id, 'PSNR': psnr, 'SSIM': ssim_val, 'RMSE': rmse})\n",
        "\n",
        "        rad_entry = {'ID': patient_id}\n",
        "        for k in rad_gt:\n",
        "            rad_entry[f'{k}_Error'] = abs(rad_gt[k] - rad_out[k])\n",
        "        radiomics_log.append(rad_entry)\n",
        "\n",
        "        # F. Simpan Gambar Bukti\n",
        "        if img_saved_count < SAVE_IMG_LIMIT and uncertainty_vol is not None:\n",
        "            mid = vol_gt.shape[0] // 2\n",
        "\n",
        "            plt.figure(figsize=(20, 5))\n",
        "            # 1. Input\n",
        "            plt.subplot(1, 5, 1); plt.imshow(vol_in[mid], cmap='gray'); plt.title(\"Input Low Dose\")\n",
        "            plt.axis('off')\n",
        "            # 2. Output\n",
        "            plt.subplot(1, 5, 2); plt.imshow(vol_out[mid], cmap='gray'); plt.title(f\"Output AI\\nPSNR: {psnr:.2f}\")\n",
        "            plt.axis('off')\n",
        "            # 3. GT\n",
        "            plt.subplot(1, 5, 3); plt.imshow(vol_gt[mid], cmap='gray'); plt.title(\"Ground Truth\")\n",
        "            plt.axis('off')\n",
        "            # 4. Uncertainty\n",
        "            plt.subplot(1, 5, 4); plt.imshow(uncertainty_vol[mid], cmap='jet'); plt.title(\"Uncertainty Map\")\n",
        "            plt.colorbar(fraction=0.046); plt.axis('off')\n",
        "            # 5. Difference\n",
        "            plt.subplot(1, 5, 5); plt.imshow(np.abs(vol_gt[mid] - vol_out[mid]), cmap='inferno'); plt.title(\"Difference Error\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(img_save_dir, f\"{patient_id}_evidence.png\"))\n",
        "            plt.close()\n",
        "            img_saved_count += 1\n",
        "\n",
        "# ==========================================\n",
        "# 6. SIMPAN HASIL AKHIR\n",
        "# ==========================================\n",
        "df_metrics = pd.DataFrame(metrics_log)\n",
        "df_radiomics = pd.DataFrame(radiomics_log)\n",
        "\n",
        "df_metrics.to_csv(os.path.join(base_output_dir, \"FINAL_Metrics.csv\"), index=False)\n",
        "df_radiomics.to_csv(os.path.join(base_output_dir, \"FINAL_Radiomics.csv\"), index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"‚úÖ TESTING SELESAI!\")\n",
        "print(\"=\"*40)\n",
        "print(f\"üìä Rata-rata PSNR: {df_metrics['PSNR'].mean():.2f} dB\")\n",
        "print(f\"üìä Rata-rata SSIM: {df_metrics['SSIM'].mean():.4f}\")\n",
        "print(f\"üì∏ {img_saved_count} Gambar bukti tersimpan di Drive.\")\n",
        "print(f\"üìÇ Lokasi: {base_output_dir}\")"
      ],
      "metadata": {
        "id": "LcvWLCuoLx9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing with Full Volume Data**"
      ],
      "metadata": {
        "id": "9-apHZASLyaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import math\n",
        "from google.colab import drive\n",
        "from tqdm.auto import tqdm\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# ==========================================\n",
        "# 1. KONFIGURASI PATH\n",
        "# ==========================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/Finpro Pencit/Training_Logs/Run_Final_V6_FineTuned_Texture/best_model_finetuned.pth'\n",
        "\n",
        "DATA_FOLDER = '/content/drive/MyDrive/Finpro Pencit/Hasil FBP/'\n",
        "\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Finpro Pencit/Hasil_Evaluasi_LinearBlend_Fixed/'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 32\n",
        "OVERLAP_PERCENT = 0.5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. DEFINISI MODEL\n",
        "# ==========================================\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(in_c, out_c, 3, padding=1), nn.BatchNorm3d(out_c), nn.ReLU(True),\n",
        "            nn.Conv3d(out_c, out_c, 3, padding=1), nn.BatchNorm3d(out_c))\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.sc = nn.Conv3d(in_c, out_c, 1) if in_c != out_c else nn.Sequential()\n",
        "    def forward(self, x): return self.relu(self.conv(x) + self.sc(x))\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super().__init__()\n",
        "        self.Wg = nn.Sequential(nn.Conv3d(F_g, F_int, 1), nn.BatchNorm3d(F_int))\n",
        "        self.Wx = nn.Sequential(nn.Conv3d(F_l, F_int, 1), nn.BatchNorm3d(F_int))\n",
        "        self.psi = nn.Sequential(nn.Conv3d(F_int, 1, 1), nn.BatchNorm3d(1), nn.Sigmoid())\n",
        "        self.relu = nn.ReLU(True)\n",
        "    def forward(self, g, x):\n",
        "        psi = self.relu(self.Wg(g) + self.Wx(x))\n",
        "        return x * self.psi(psi)\n",
        "\n",
        "class Lightweight3DUNet(nn.Module):\n",
        "    def __init__(self, in_c=1, out_c=1):\n",
        "        super().__init__()\n",
        "        f = [16, 32, 64, 128]\n",
        "        self.enc1 = ResBlock(in_c, f[0]); self.p1 = nn.MaxPool3d(2)\n",
        "        self.enc2 = ResBlock(f[0], f[1]); self.p2 = nn.MaxPool3d(2)\n",
        "        self.enc3 = ResBlock(f[1], f[2]); self.p3 = nn.MaxPool3d(2)\n",
        "        self.bot = ResBlock(f[2], f[3])\n",
        "\n",
        "        self.up3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att3 = AttentionBlock(f[3], f[2], f[2])\n",
        "        self.dec3 = ResBlock(f[3]+f[2], f[2])\n",
        "\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att2 = AttentionBlock(f[2], f[1], f[1])\n",
        "        self.dec2 = ResBlock(f[2]+f[1], f[1])\n",
        "\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "        self.att1 = AttentionBlock(f[1], f[0], f[0])\n",
        "        self.dec1 = ResBlock(f[1]+f[0], f[0])\n",
        "\n",
        "        self.out = nn.Conv3d(f[0], out_c, 1)\n",
        "        self.dropout = nn.Dropout3d(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x); p1 = self.p1(e1)\n",
        "        e2 = self.enc2(p1); p2 = self.p2(e2)\n",
        "        e3 = self.enc3(p2); p3 = self.p3(e3)\n",
        "        b = self.bot(p3)\n",
        "\n",
        "        d3 = self.up3(b); x3 = self.att3(d3, e3); d3 = self.dec3(torch.cat([x3, d3], 1))\n",
        "        d2 = self.up2(d3); x2 = self.att2(d2, e2); d2 = self.dec2(torch.cat([x2, d2], 1))\n",
        "        d1 = self.up1(d2); x1 = self.att1(d1, e1); d1 = self.dec1(torch.cat([x1, d1], 1))\n",
        "        return self.out(self.dropout(d1))\n",
        "\n",
        "# ==========================================\n",
        "# 3. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def normalize_data(data):\n",
        "    \"\"\"Normalisasi standar 0-1\"\"\"\n",
        "    v_min, v_max = data.min(), data.max()\n",
        "    if v_max - v_min > 0: return (data - v_min) / (v_max - v_min)\n",
        "    return data\n",
        "\n",
        "def calculate_cnr(vol):\n",
        "    \"\"\"Contrast-to-Noise Ratio\"\"\"\n",
        "    flat = vol.flatten()\n",
        "    thresh = np.mean(flat)\n",
        "    sig = flat[flat > thresh]; bg = flat[flat <= thresh]\n",
        "    if len(sig) < 5 or len(bg) < 5: return 0.0\n",
        "    return abs(np.mean(sig) - np.mean(bg)) / (np.std(bg) + 1e-6)\n",
        "\n",
        "# --- FUNGSI BOBOT LINEAR (PYRAMID) ---\n",
        "def get_linear_weight_map(patch_size):\n",
        "    \"\"\"\n",
        "    Membuat bobot berbentuk piramida.\n",
        "    Tengah = 1.0 (Kuat), Pinggir = 0.0 (Lemah).\n",
        "    Saat dijahit, bagian lemah akan digantikan oleh bagian kuat dari patch sebelahnya.\n",
        "    Hasil: Mulus tanpa blur.\n",
        "    \"\"\"\n",
        "    # 1D Linear ramp\n",
        "    vals = np.linspace(0, 1, patch_size)\n",
        "    vals = np.minimum(vals, 1 - vals) * 2\n",
        "\n",
        "    # Buat 3D Weight Map\n",
        "    w_x, w_y, w_z = np.meshgrid(vals, vals, vals, indexing='ij')\n",
        "    weight_map = w_x * w_y * w_z\n",
        "\n",
        "    return np.maximum(weight_map, 1e-4)\n",
        "\n",
        "# ==========================================\n",
        "# 4. INFERENCE ENGINE (LINEAR BLENDING)\n",
        "# ==========================================\n",
        "def predict_linear_blending(model, vol_in, patch_size, overlap=0.5):\n",
        "    model.eval()\n",
        "    d, h, w = vol_in.shape\n",
        "    stride = int(patch_size * (1 - overlap))\n",
        "\n",
        "    # Padding\n",
        "    pad_d = (stride - d % stride) % stride\n",
        "    pad_h = (stride - h % stride) % stride\n",
        "    pad_w = (stride - w % stride) % stride\n",
        "\n",
        "    # Extra padding\n",
        "    pad_extra = patch_size\n",
        "    vol_padded = np.pad(vol_in, ((0, pad_d + pad_extra), (0, pad_h + pad_extra), (0, pad_w + pad_extra)), mode='reflect')\n",
        "\n",
        "    d_p, h_p, w_p = vol_padded.shape\n",
        "\n",
        "    # Penampung Hasil\n",
        "    output_sum = np.zeros_like(vol_padded)\n",
        "    weight_sum = np.zeros_like(vol_padded)\n",
        "\n",
        "    # Buat Weight Map\n",
        "    patch_weight = torch.from_numpy(get_linear_weight_map(patch_size)).float().to(DEVICE)\n",
        "\n",
        "    print(\"   ‚è≥ Stitching with Linear Blending (Seamless)...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for z in range(0, d_p - patch_size, stride):\n",
        "            for y in range(0, h_p - patch_size, stride):\n",
        "                for x in range(0, w_p - patch_size, stride):\n",
        "\n",
        "                    patch_in = vol_padded[z:z+patch_size, y:y+patch_size, x:x+patch_size]\n",
        "\n",
        "                    if patch_in.shape != (patch_size, patch_size, patch_size): continue\n",
        "\n",
        "                    t_in = torch.from_numpy(patch_in).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "                    t_out = model(t_in).squeeze() # (32, 32, 32)\n",
        "\n",
        "                    output_sum[z:z+patch_size, y:y+patch_size, x:x+patch_size] += (t_out * patch_weight).cpu().numpy()\n",
        "                    weight_sum[z:z+patch_size, y:y+patch_size, x:x+patch_size] += patch_weight.cpu().numpy()\n",
        "\n",
        "    # Normalisasi (Weighted Average)\n",
        "    reconstructed = output_sum / (weight_sum + 1e-8)\n",
        "\n",
        "    return reconstructed[:d, :h, :w]\n",
        "\n",
        "# ==========================================\n",
        "# 5. MAIN EVALUATION LOOP\n",
        "# ==========================================\n",
        "def run_evaluation():\n",
        "    print(f\"üß† Loading Model: {os.path.basename(MODEL_PATH)}\")\n",
        "\n",
        "    # Load Arsitektur Lightweight\n",
        "    model = Lightweight3DUNet().to(DEVICE)\n",
        "    if os.path.exists(MODEL_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "        print(\"‚úÖ Model loaded successfully!\")\n",
        "    else:\n",
        "        print(\"‚ùå Model path not found!\"); return\n",
        "\n",
        "    # Cari file\n",
        "    all_files = sorted(glob.glob(os.path.join(DATA_FOLDER, \"processed_input_*.npy\")))\n",
        "    input_files = all_files[-3:]\n",
        "\n",
        "    results_log = []\n",
        "\n",
        "    for i, in_path in enumerate(input_files):\n",
        "        filename = os.path.basename(in_path)\n",
        "        print(f\"\\nProcessing [{i+1}/3]: {filename}\")\n",
        "\n",
        "        # Load Data\n",
        "        raw_in = np.load(in_path)\n",
        "        vol_in = normalize_data(raw_in)\n",
        "\n",
        "        target_path = os.path.join(DATA_FOLDER, filename.replace(\"processed_input_\", \"processed_target_\"))\n",
        "        vol_gt = normalize_data(np.load(target_path)) if os.path.exists(target_path) else None\n",
        "\n",
        "        if vol_gt is not None and vol_gt.shape != vol_in.shape:\n",
        "            vol_gt = vol_gt[:vol_in.shape[0], :vol_in.shape[1], :vol_in.shape[2]]\n",
        "\n",
        "        # --- PREDICT ---\n",
        "        vol_out = predict_linear_blending(model, vol_in, PATCH_SIZE, OVERLAP_PERCENT)\n",
        "\n",
        "        # --- METRICS ---\n",
        "        metrics = {'PSNR': 0, 'SSIM': 0, 'RMSE': 0}\n",
        "        if vol_gt is not None:\n",
        "            metrics['PSNR'] = psnr(vol_gt, vol_out, data_range=1.0)\n",
        "            metrics['SSIM'] = ssim(vol_gt, vol_out, data_range=1.0)\n",
        "            metrics['RMSE'] = math.sqrt(np.mean((vol_gt - vol_out)**2))\n",
        "\n",
        "        cnr_in = calculate_cnr(vol_in)\n",
        "        cnr_out = calculate_cnr(vol_out)\n",
        "        cnr_gt = calculate_cnr(vol_gt) if vol_gt is not None else 0\n",
        "\n",
        "        results_log.append({\n",
        "            'Filename': filename,\n",
        "            'PSNR': metrics['PSNR'], 'SSIM': metrics['SSIM'], 'RMSE': metrics['RMSE'],\n",
        "            'CNR_In': cnr_in, 'CNR_Out': cnr_out, 'CNR_GT': cnr_gt,\n",
        "            'CNR_Improv': cnr_out - cnr_in\n",
        "        })\n",
        "\n",
        "        print(f\"   -> PSNR: {metrics['PSNR']:.2f} | SSIM: {metrics['SSIM']:.4f} | RMSE: {metrics['RMSE']:.4f}\")\n",
        "        print(f\"   -> CNR Improv: {cnr_out - cnr_in:.4f}\")\n",
        "\n",
        "        # --- VISUALIZATION ---\n",
        "        mid = vol_out.shape[0] // 2\n",
        "        fig = plt.figure(figsize=(20, 12))\n",
        "        gs = fig.add_gridspec(3, 4)\n",
        "\n",
        "        # Row 1: Images\n",
        "        ax1 = fig.add_subplot(gs[0, 0]); ax1.imshow(vol_in[mid], cmap='gray'); ax1.set_title(\"Input (FBP)\")\n",
        "        ax2 = fig.add_subplot(gs[0, 1]); ax2.imshow(vol_out[mid], cmap='gray'); ax2.set_title(\"AI Output (Natural)\")\n",
        "        ax3 = fig.add_subplot(gs[0, 2]);\n",
        "        if vol_gt is not None: ax3.imshow(vol_gt[mid], cmap='gray'); ax3.set_title(\"Ground Truth\")\n",
        "        else: ax3.axis('off')\n",
        "\n",
        "        # CNR Chart\n",
        "        ax_chart = fig.add_subplot(gs[0, 3])\n",
        "        ax_chart.bar(['In', 'Out', 'GT'], [cnr_in, cnr_out, cnr_gt], color=['gray', 'blue', 'green'])\n",
        "        ax_chart.set_title(\"CNR Comparison\"); ax_chart.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # Row 2: Density Maps (Heatmap)\n",
        "        ax4 = fig.add_subplot(gs[1, 0]); im4 = ax4.imshow(vol_in[mid], cmap='jet'); ax4.set_title(\"Density (In)\"); plt.colorbar(im4, ax=ax4)\n",
        "        ax5 = fig.add_subplot(gs[1, 1]); im5 = ax5.imshow(vol_out[mid], cmap='jet'); ax5.set_title(\"Density (Out)\"); plt.colorbar(im5, ax=ax5)\n",
        "        ax6 = fig.add_subplot(gs[1, 2]);\n",
        "        if vol_gt is not None: im6 = ax6.imshow(vol_gt[mid], cmap='jet'); ax6.set_title(\"Density (GT)\"); plt.colorbar(im6, ax=ax6)\n",
        "        else: ax6.axis('off')\n",
        "\n",
        "        # Row 3: Error Map\n",
        "        ax7 = fig.add_subplot(gs[2, 1]);\n",
        "        err = np.abs(vol_gt - vol_out) if vol_gt is not None else np.zeros_like(vol_out)\n",
        "        im7 = ax7.imshow(err[mid], cmap='inferno'); ax7.set_title(f\"Error Map (RMSE: {metrics['RMSE']:.4f})\"); plt.colorbar(im7, ax=ax7)\n",
        "\n",
        "        for ax in [ax1, ax2, ax3, ax4, ax5, ax6, ax7]: ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f\"Eval_Natural_{filename.replace('.npy','.png')}\"))\n",
        "        plt.show()\n",
        "\n",
        "    if results_log:\n",
        "        pd.DataFrame(results_log).to_csv(os.path.join(OUTPUT_DIR, \"Final_Report_Natural.csv\"), index=False)\n",
        "        print(\"\\n‚úÖ DONE.\")\n",
        "        print(pd.DataFrame(results_log)[['Filename', 'PSNR', 'SSIM', 'RMSE']].to_string())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation()"
      ],
      "metadata": {
        "id": "1IELHCYJL06m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2D Multi-Level Wavelet Convolutional Neural Network (MWCNN)**"
      ],
      "metadata": {
        "id": "0Pf3eIP_NFRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training & Validation**"
      ],
      "metadata": {
        "id": "eix_u0yENQx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ===============================\n",
        "# 1. Dataset 2D FBP\n",
        "# ===============================\n",
        "class FBP2DDataset(Dataset):\n",
        "    def __init__(self, fbp_folder, gt_folder):\n",
        "        self.fbp_files = sorted([os.path.join(fbp_folder, f) for f in os.listdir(fbp_folder)])\n",
        "        self.gt_files = sorted([os.path.join(gt_folder, f) for f in os.listdir(gt_folder)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fbp_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.load(self.fbp_files[idx])\n",
        "        y = np.load(self.gt_files[idx])\n",
        "\n",
        "        # Normalize\n",
        "        x = (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
        "        y = (y - y.min()) / (y.max() - y.min() + 1e-8)\n",
        "\n",
        "        # To tensor + channel dim\n",
        "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)  # [1,H,W]\n",
        "        y = torch.tensor(y, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# ===============================\n",
        "# 2. Model MultiWave CNN 2D\n",
        "# ===============================\n",
        "class MultiWaveBlock2D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.c3 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.c5 = nn.Conv2d(in_ch, out_ch, 5, padding=2)\n",
        "        self.c7 = nn.Conv2d(in_ch, out_ch, 7, padding=3)\n",
        "        self.bn = nn.BatchNorm2d(out_ch * 3)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(torch.cat([\n",
        "            self.c3(x), self.c5(x), self.c7(x)\n",
        "        ], dim=1)))\n",
        "\n",
        "class MultiWaveCNN2D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.b1 = MultiWaveBlock2D(1, 16)\n",
        "        self.b2 = MultiWaveBlock2D(48, 32)\n",
        "        self.b3 = MultiWaveBlock2D(96, 64)\n",
        "        self.out = nn.Conv2d(192, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.b3(x)\n",
        "        return self.out(x)\n",
        "\n",
        "# ===============================\n",
        "# 3. Load data & split\n",
        "# ===============================\n",
        "fbp_folder = \"/content/drive/MyDrive/Tugas SMT 5/Pencit/Hasil FBP 2D\"\n",
        "gt_folder = \"/content/drive/MyDrive/Tugas SMT 5/Pencit/Ground Truth FBP 2D\"\n",
        "\n",
        "dataset = FBP2DDataset(fbp_folder, gt_folder)\n",
        "\n",
        "train_idx, val_idx = train_test_split(np.arange(len(dataset)), test_size=0.1, random_state=42)\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
        "\n",
        "BATCH_SIZE = 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# ===============================\n",
        "# 4. Setup model, loss, optimizer, scheduler\n",
        "# ===============================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiWaveCNN2D().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# ===============================\n",
        "# 5. Training loop dengan checkpoint\n",
        "# ===============================\n",
        "EPOCHS = 25\n",
        "patience = 10\n",
        "early_stop_counter = 0\n",
        "best_val = float('inf')\n",
        "\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/Tugas SMT 5/Pencit/checkpoint_latest.pth\"\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    print(\"üîÅ Resuming training from checkpoint...\")\n",
        "\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "\n",
        "    start_epoch = checkpoint[\"epoch\"]\n",
        "    best_val = checkpoint[\"best_val\"]\n",
        "\n",
        "    print(f\"‚úÖ Resumed from epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"üÜï No checkpoint found, starting from epoch 1\")\n",
        "\n",
        "for e in range(start_epoch, EPOCHS):\n",
        "\n",
        "    # =======================\n",
        "    # TRAIN\n",
        "    # =======================\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for x, y in tqdm(train_loader, desc=f\"Epoch {e+1} Training\"):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # =======================\n",
        "    # VALIDATION\n",
        "    # =======================\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            val_loss += criterion(model(x), y).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # =======================\n",
        "    # SCHEDULER\n",
        "    # =======================\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # =======================\n",
        "    # BEST MODEL\n",
        "    # =======================\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        early_stop_counter = 0\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    # =======================\n",
        "    # SAVE CHECKPOINT (SETIAP EPOCH)\n",
        "    # =======================\n",
        "    torch.save({\n",
        "        \"epoch\": e + 1,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
        "        \"best_val\": best_val\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "    # =======================\n",
        "    # LOG\n",
        "    # =======================\n",
        "    print(\n",
        "        f\"Epoch {e+1:02d} | \"\n",
        "        f\"Train: {train_loss:.6f} | \"\n",
        "        f\"Val: {val_loss:.6f} | \"\n",
        "        f\"Best: {best_val:.6f}\"\n",
        "    )\n",
        "\n",
        "    # =======================\n",
        "    # EARLY STOPPING\n",
        "    # =======================\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f\"‚õî No improvement in {patience} epochs, stopping early.\")\n",
        "        break"
      ],
      "metadata": {
        "id": "hxo7SebINQZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "1QEkB4F2NWLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def evaluate(model, loader, device, max_batches=3):\n",
        "    model.eval()\n",
        "\n",
        "    psnr_list, ssim_list, rmse_list, cnr_list = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            x = x.cpu().numpy()\n",
        "            y = y.cpu().numpy()\n",
        "            pred = pred.cpu().numpy()\n",
        "\n",
        "            for b in range(x.shape[0]):\n",
        "                inp = x[b, 0]\n",
        "                gt  = y[b, 0]\n",
        "                out = pred[b, 0]\n",
        "\n",
        "                diff = np.abs(gt - out)\n",
        "\n",
        "                # ======================\n",
        "                # METRIK\n",
        "                # ======================\n",
        "                psnr_val = psnr(gt, out, data_range=1.0)\n",
        "                ssim_val = ssim(gt, out, data_range=1.0)\n",
        "                rmse_val = np.sqrt(np.mean((gt - out) ** 2))\n",
        "\n",
        "                # ======================\n",
        "                # CNR\n",
        "                # ======================\n",
        "                h, w = gt.shape\n",
        "                roi = np.s_[h//3:h//2, w//3:w//2]\n",
        "                bg  = np.s_[0:h//5, 0:w//5]\n",
        "\n",
        "                cnr_val = compute_cnr(out, roi, bg)\n",
        "\n",
        "                psnr_list.append(psnr_val)\n",
        "                ssim_list.append(ssim_val)\n",
        "                rmse_list.append(rmse_val)\n",
        "                cnr_list.append(cnr_val)\n",
        "\n",
        "                # ======================\n",
        "                # PRINT\n",
        "                # ======================\n",
        "                print(\n",
        "                    f\"PSNR: {psnr_val:.2f} dB | \"\n",
        "                    f\"SSIM: {ssim_val:.4f} | \"\n",
        "                    f\"RMSE: {rmse_val:.5f} | \"\n",
        "                    f\"CNR: {cnr_val:.3f}\"\n",
        "                )\n",
        "\n",
        "                # ======================\n",
        "                # VISUALISASI\n",
        "                # ======================\n",
        "                plt.figure(figsize=(16,4))\n",
        "\n",
        "                plt.subplot(1,4,1)\n",
        "                plt.imshow(inp, cmap='gray')\n",
        "                plt.title(\"Input (FBP)\")\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1,4,2)\n",
        "                plt.imshow(out, cmap='gray')\n",
        "                plt.title(\"Output (MWCNN)\")\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1,4,3)\n",
        "                plt.imshow(gt, cmap='gray')\n",
        "                plt.title(\"Ground Truth\")\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(1,4,4)\n",
        "                plt.imshow(diff, cmap='hot')\n",
        "                plt.title(\"Difference Map\")\n",
        "                plt.colorbar(fraction=0.046)\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "    # ======================\n",
        "    # RATA-RATA\n",
        "    # ======================\n",
        "    print(\"\\n===== RATA-RATA EVALUASI =====\")\n",
        "    print(f\"PSNR  : {np.mean(psnr_list):.2f} ¬± {np.std(psnr_list):.2f}\")\n",
        "    print(f\"SSIM  : {np.mean(ssim_list):.4f}\")\n",
        "    print(f\"RMSE  : {np.mean(rmse_list):.5f}\")\n",
        "    print(f\"CNR   : {np.mean(cnr_list):.3f}\")"
      ],
      "metadata": {
        "id": "wyeFei3sN4DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def compare_fbp_vs_mwcnn(model, loader, device, max_batches=3):\n",
        "    model.eval()\n",
        "\n",
        "    metrics = {\n",
        "        \"FBP\":  {\"psnr\": [], \"ssim\": [], \"rmse\": [], \"cnr\": []},\n",
        "        \"MWCNN\":{\"psnr\": [], \"ssim\": [], \"rmse\": [], \"cnr\": []}\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            x = x.cpu().numpy()\n",
        "            y = y.cpu().numpy()\n",
        "            pred = pred.cpu().numpy()\n",
        "\n",
        "            for b in range(x.shape[0]):\n",
        "                fbp = x[b,0]\n",
        "                gt  = y[b,0]\n",
        "                out = pred[b,0]\n",
        "\n",
        "                # ======================\n",
        "                # METRIK FBP\n",
        "                # ======================\n",
        "                metrics[\"FBP\"][\"psnr\"].append(psnr(gt, fbp, data_range=1.0))\n",
        "                metrics[\"FBP\"][\"ssim\"].append(ssim(gt, fbp, data_range=1.0))\n",
        "                metrics[\"FBP\"][\"rmse\"].append(np.sqrt(np.mean((gt - fbp)**2)))\n",
        "\n",
        "                # ======================\n",
        "                # METRIK MWCNN\n",
        "                # ======================\n",
        "                metrics[\"MWCNN\"][\"psnr\"].append(psnr(gt, out, data_range=1.0))\n",
        "                metrics[\"MWCNN\"][\"ssim\"].append(ssim(gt, out, data_range=1.0))\n",
        "                metrics[\"MWCNN\"][\"rmse\"].append(np.sqrt(np.mean((gt - out)**2)))\n",
        "\n",
        "                # ======================\n",
        "                # CNR\n",
        "                # ======================\n",
        "                h, w = gt.shape\n",
        "                roi = np.s_[h//3:h//2, w//3:w//2]\n",
        "                bg  = np.s_[0:h//5, 0:w//5]\n",
        "\n",
        "                metrics[\"FBP\"][\"cnr\"].append(compute_cnr(fbp, roi, bg))\n",
        "                metrics[\"MWCNN\"][\"cnr\"].append(compute_cnr(out, roi, bg))\n",
        "\n",
        "    # ======================\n",
        "    # RATA-RATA\n",
        "    # ======================\n",
        "    print(\"\\n========== PERBANDINGAN KINERJA ==========\")\n",
        "\n",
        "    for m in [\"psnr\", \"ssim\", \"rmse\", \"cnr\"]:\n",
        "        fbp_val = np.mean(metrics[\"FBP\"][m])\n",
        "        mw_val  = np.mean(metrics[\"MWCNN\"][m])\n",
        "\n",
        "        if m in [\"psnr\", \"ssim\", \"cnr\"]:\n",
        "            label = \"‚úÖ Better\" if mw_val > fbp_val else \"‚ùå Worse\"\n",
        "        else:  # RMSE\n",
        "            label = \"‚úÖ Better\" if mw_val < fbp_val else \"‚ùå Worse\"\n",
        "\n",
        "        print(f\"{m.upper():5s} | FBP: {fbp_val:.4f} | MWCNN: {mw_val:.4f} ‚Üí {label}\")"
      ],
      "metadata": {
        "id": "tcTmjGt-N4je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_fbp_vs_mwcnn(model, val_loader, device)"
      ],
      "metadata": {
        "id": "yS0MxcHoOKPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}